{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, re, datetime\n",
    "from getpass import getpass                # Allows for an entry field to avoid hard-coded API keys\n",
    "from cognite.client import CogniteClient   # Python SDK\n",
    "from cognite.client.utils import timestamp_to_ms, ms_to_datetime  # Functions that convert datetime to ms since epoch and vice versa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup of Cognite SDK for communicating with CDF (will ask for API-key to Aker BPs 'prod'-environment in CDF, i.e. 'akerbp'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ················································\n"
     ]
    }
   ],
   "source": [
    "api_key = getpass()\n",
    "client = CogniteClient(\n",
    "    api_key = api_key,\n",
    "    project=\"akerbp\",\n",
    "    client_name=\"DSHub\",\n",
    "    base_url=\"https://api.cognitedata.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class for fetching events from CDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following class is an example of how you could implement an \"event fetcher\" to be used in CrewLog. After the object is declared (`my_fetcher = CrewLogEventFetcher()`) and Aker BP assets are added (e.g. `my_fetcher.add_akerbp_asset('ULA', my_fetcher.get_abb_events, [<cdf-dataset-id>, ...], [<cdf-asset-id>, ...])`), you can fetch events from CDF like this: `events = my_fetcher.fetch_events('ULA')`. The first call will be made from the start of the current shift when the object was declared, e.g. 07:00 on the current day if the class was declared between 07:00 and 19:00. Succeeding `my_fetcher.fetch_events()` calls will only fetch events from the last time a call was made and to the current time of the call. \n",
    "\n",
    "E.g. If the object was declared at 14:00, the first call will fetch events from 07:00-14:00. If a second call is run at 16:00, it will only fetch events from 14:00-16:00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class made to fetch events from CDF for CrewLog\n",
    "class CrewLogEventFetcher:\n",
    "    \n",
    "    # Initialization function\n",
    "    def __init__(self):\n",
    "        self.switcher = {}\n",
    "        self.data_set_ids = {}\n",
    "        self.asset_subtree_ids = {}\n",
    "        self.last_timestamps = {}\n",
    "    \n",
    "    \n",
    "    # Adds an Aker BP asset to fetch events from\n",
    "    # Parameters:\n",
    "    # - 'akerbp_asset_abbr' must be a three letter Aker BP asset abbrieviation (e.g. 'ULA')\n",
    "    # - 'get_events_function' must be a function like e.g. 'get_abb_events'\n",
    "    # - 'data_set_ids' must be a list of CDF data set IDs (e.g. [123, 456, ...])\n",
    "    # - 'asset_ids' must be a list of CDF asset IDs (e.g. [123, 456, ...])\n",
    "    #\n",
    "    def add_akerbp_asset(self, akerbp_asset_abbr, get_events_function, data_set_ids = None, asset_ids = None):\n",
    "        \n",
    "        # Declare essentials\n",
    "        self.switcher[akerbp_asset_abbr] = get_events_function    # Asset specific function (e.g. self.get_abb_events)\n",
    "        self.data_set_ids[akerbp_asset_abbr] = data_set_ids       # List of relevant CDF dataset ids\n",
    "        self.asset_subtree_ids[akerbp_asset_abbr] = asset_ids     # List of relevant CDF asset ids\n",
    "        \n",
    "        # Set the last time an API call was made to be the start of the current shift\n",
    "        # i.e. 0700 for day shift, 1900 for night shift\n",
    "        timeref = datetime.datetime.today()\n",
    "        if timeref.hour < 7:\n",
    "            timeref = timeref - datetime.timedelta(days=1)\n",
    "            self.last_timestamps[akerbp_asset_abbr] = datetime.datetime(timeref.year, timeref.month, timeref.day, 19)\n",
    "        elif timeref.hour > 7 and timeref.hour < 19:\n",
    "            self.last_timestamps[akerbp_asset_abbr] = datetime.datetime(timeref.year, timeref.month, timeref.day, 7)\n",
    "        else:\n",
    "            self.last_timestamps[akerbp_asset_abbr] = datetime.datetime(timeref.year, timeref.month, timeref.day, 19)\n",
    "    \n",
    "    \n",
    "    # Function that returns the start_time for an event - for sorting purposes\n",
    "    # - 'event' must be a CDF event object\n",
    "    #\n",
    "    def sort_by_start_time(self, event):\n",
    "        return event.start_time\n",
    "    \n",
    "    \n",
    "    # Shared function for fetching control system events from CDF - independent of control system supplier\n",
    "    # The control system specific functions below makes use of this function\n",
    "    # Parameters:\n",
    "    # - 'akerbp_asset_abbr' must be a three letter Aker BP asset abbrieviation (e.g. 'ULA')\n",
    "    # - 'metadata_sets' must be a list of dictionaries (e.g. [{}, ...] - see get_abb_events() function)\n",
    "    # - 'from_time' is optional, but must be a datetime-object of the time you want to fetch events FROM\n",
    "    # - 'to_time' is optional, but must be a datetime-object of the time you want to fetch event TO\n",
    "    #\n",
    "    def get_cdf_events(self, akerbp_asset_abbr, metadata_sets, from_time = None, to_time = None):        \n",
    "        events = []\n",
    "        \n",
    "        # If function call has no 'from_time' or 'to_time', a standard time interval will be used in the API call\n",
    "        # Standard time interval will be from the last time an API call was made to the current time, to eliminate duplicates\n",
    "        if not from_time: from_time = self.last_timestamps[akerbp_asset_abbr]\n",
    "        if not to_time: to_time = datetime.datetime.now()\n",
    "        \n",
    "        # Because of API limitations we need to run multiple API calls when we're looking for events that can hold \n",
    "        # different attributes or values. Each set of metadata in metadata_sets represents a single API call.\n",
    "        for metadata in metadata_sets:\n",
    "            \n",
    "            # Loop through sets of asset subtree ids (max. 100 assets in a single API call)\n",
    "            i = 0\n",
    "            while i < len(self.asset_subtree_ids[akerbp_asset_abbr]):\n",
    "                # End index to ensure a maximum of 100 assets for each call\n",
    "                j = min(i+100, len(self.asset_subtree_ids[akerbp_asset_abbr]))\n",
    "                \n",
    "                # API call to CDF - fetching all events matching the given parameters\n",
    "                temp_events = client.events.list(\n",
    "                    start_time = {\n",
    "                        'min': timestamp_to_ms(from_time),\n",
    "                        'max': timestamp_to_ms(to_time)\n",
    "                    },\n",
    "                    metadata = metadata,\n",
    "                    asset_subtree_ids = self.asset_subtree_ids[akerbp_asset_abbr][i:j],\n",
    "                    data_set_ids = self.data_set_ids[akerbp_asset_abbr],\n",
    "                    sort = ['startTime:asc'],\n",
    "                    limit = -1\n",
    "                )\n",
    "                # Store the results from all individual API calls in one list of events\n",
    "                events.extend(temp_events)\n",
    "                \n",
    "                # Update start index for asset list to be used in next call\n",
    "                i += 100\n",
    "        \n",
    "        # Update the variable that keeps track of when the last time an API call was made\n",
    "        # so that only events from this time is fetched for the next API call\n",
    "        self.last_timestamps[akerbp_asset_abbr] = to_time\n",
    "        \n",
    "        # Sort events by start_time (chronological order)\n",
    "        events.sort(key=self.sort_by_start_time)\n",
    "        \n",
    "        # Return sorted list of events\n",
    "        return events\n",
    "    \n",
    "    \n",
    "    # Individual function for ABB events, in case other control systems need unique filters\n",
    "    # - 'akerbp_asset_abbr' must be a three letter Aker BP asset abbrieviation (e.g. 'ULA')\n",
    "    #\n",
    "    def get_abb_events(self, akerbp_asset_abbr):\n",
    "        \n",
    "        # Filters to be used in API call(s)\n",
    "        abb_metadata_pre_filters = {\n",
    "            'severity': ['801', '802', '803', '804', '809',\n",
    "                         '901', '902', '903', '904', '909'],\n",
    "            'newState': ['3']\n",
    "        }\n",
    "        # Valhall has two more systems and therefore more severity codes\n",
    "        if akerbp_asset_abbr == 'VAL': \n",
    "            abb_metadata_pre_filters['severity'].extend(['805', '806', '905', '906'])\n",
    "        \n",
    "        # Filters to be used on API result\n",
    "        abb_metadata_post_filters = {\n",
    "            'alarmState': ['ACT'],\n",
    "            'AlarmState': ['ACT']\n",
    "        }\n",
    "        \n",
    "        # Build sets of metadata filters to be used in API call(s)\n",
    "        # NOTE: add an empty dictionary to 'metadata_sets' if no metadata filters are needed\n",
    "        metadata_sets = []\n",
    "        for severity in abb_metadata_pre_filters['severity']:\n",
    "            for new_state in abb_metadata_pre_filters['newState']:\n",
    "                metadata = {\n",
    "                    'severity': severity,\n",
    "                    'newState': new_state\n",
    "                }\n",
    "                metadata_sets.append(metadata)\n",
    "        \n",
    "        # API call(s)\n",
    "        res_events = self.get_cdf_events(akerbp_asset_abbr, metadata_sets)\n",
    "        \n",
    "        # Filter API results\n",
    "        events = res_events.copy()\n",
    "        for event in res_events:\n",
    "            \n",
    "            # Loop through the filters to be used on the API result\n",
    "            for key, values in abb_metadata_post_filters.items():\n",
    "                attribute = event.metadata.get(key)\n",
    "                \n",
    "                # If an event does not hold the desired value - remove said event from the results\n",
    "                if attribute and attribute not in values:\n",
    "                    events.remove(event)\n",
    "                    break\n",
    "        \n",
    "        # Return filtered list of events\n",
    "        return events\n",
    "    \n",
    "    \n",
    "    # ---- TO BE IMPLEMENTED --------------------------------------------------------\n",
    "    # NOTE: See 'get_abb_events()' function for an example on how to implement this\n",
    "    # -------------------------------------------------------------------------------\n",
    "    # Individual function for Kongsberg events, in case other control systems need unique filters\n",
    "    def get_kongsberg_events(self, akerbp_asset_abbr):\n",
    "        # Build sets of metadata filters to be used in API call(s)\n",
    "        metadata_sets = []\n",
    "        # API call(s)\n",
    "        res_events = self.get_cdf_events(akerbp_asset_abbr, metadata_sets)\n",
    "        # Filter API results\n",
    "        events = res_events\n",
    "        # Return list of filtered events\n",
    "        return events\n",
    "    \n",
    "    \n",
    "    # ---- TO BE IMPLEMENTED --------------------------------------------------------\n",
    "    # NOTE: See 'get_abb_events()' function for an example on how to implement this\n",
    "    # -------------------------------------------------------------------------------\n",
    "    # Individual function for Siemens events, in case other control systems need unique filters\n",
    "    def get_siemens_events(self, akerbp_asset_abbr):\n",
    "        # Build sets of metadata filters to be used in API call(s)\n",
    "        metadata_sets = []\n",
    "        # API call(s)\n",
    "        res_events = self.get_cdf_events(akerbp_asset_abbr, metadata_sets)\n",
    "        # Filter API results\n",
    "        events = res_events\n",
    "        # Return list of filtered events\n",
    "        return events\n",
    "    \n",
    "    \n",
    "    # Print error message if an Aker BP asset have not been added to CrewLogEventFetcher\n",
    "    def error_function(self, akerbp_asset_abbr):\n",
    "        print(f\"Asset '{akerbp_asset_abbr}' was not found.\")\n",
    "    \n",
    "    \n",
    "    # Main function to fetch all events from the given Aker BP asset since last time function was run\n",
    "    # - 'akerbp_asset_abbr' must be a three letter Aker BP asset abbrieviation (e.g. 'ULA')\n",
    "    #\n",
    "    def fetch_events(self, akerbp_asset_abbr):\n",
    "        return self.switcher.get(akerbp_asset_abbr, self.error_function)(akerbp_asset_abbr)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class for generating CDF asset list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following classes are made to generate lists of asset IDs, to be used in e.g. `my_fetcher.add_akerbp_asset(..., asset_ids)`.\n",
    "\n",
    "After a `CrewLogAssetFetcher` object is declared (`my_asset_fetcher = CrewLogAssetFetcher()`) and Aker BP assets are added (e.g. `my_asset_fetcher.add_akerbp_asset('ULA', '<.csv-filename>', [<cdf-dataset-id>, ...])`), you can fetch CDF a list of asset IDs from CDF like this: `asset_ids = my_asset_fetcher.fetch_assets('ULA')`. This list of asset IDs is to be used when adding Aker BP assets to the `CrewLogEventFetcher` object mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just a class to make code a bit more readable\n",
    "class CrewLogTag():\n",
    "    \n",
    "    # Must have a tag name as parameter and optionally a list of alternative tag names (e.g. ABB control system tag for an Aker BP tag)\n",
    "    def __init__(self, tag_name, alt_tag_names = []):\n",
    "        self.name = tag_name\n",
    "        self.alt_tags = alt_tag_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class made to generate list of relevant CDF assets\n",
    "class CrewLogAssetFetcher():\n",
    "    \n",
    "    # Initialization function\n",
    "    def __init__(self):\n",
    "        self.csv_filenames = {}\n",
    "        self.data_set_ids = {}\n",
    "        self.asset_ids = {}\n",
    "    \n",
    "    \n",
    "    # Add an Aker BP asset to fetch events from\n",
    "    # Parameters:\n",
    "    # - 'akerbp_asset_abbr' must be a three letter Aker BP asset abbrieviation (e.g. 'ULA')\n",
    "    # - 'csv_filename' must be a .csv-file in the 'data' directory (e.g. 'main_components_ula.csv')\n",
    "    # - 'data_set_ids' must be a list of CDF data set IDs (e.g. [123, 456, ...])\n",
    "    #\n",
    "    def add_akerbp_asset(self, akerbp_asset_abbr, csv_filename, data_set_ids = None):\n",
    "        \n",
    "        # Declare essentials\n",
    "        self.csv_filenames[akerbp_asset_abbr] = csv_filename      # List of relevant CDF asset ids\n",
    "        self.data_set_ids[akerbp_asset_abbr] = data_set_ids       # List of relevant CDF dataset ids\n",
    "    \n",
    "    \n",
    "    # This function reads all tags from the given .csv-file and creates a list of CrewLogTag objects\n",
    "    # that has a name and possibly a list of alternative tag names (e.g. ABB tags)\n",
    "    # - 'csv_filename' must be a .csv-file in the 'data' directory (e.g. 'main_components_ula.csv')\n",
    "    #\n",
    "    def import_tags_from_csv(self, csv_filename):\n",
    "        with open(f'../data/input/{csv_filename}', 'rt', encoding='utf-8-sig') as f:\n",
    "            data = csv.reader(f, delimiter=\";\")    # .csv-file must be semicolon-delimited\n",
    "            header = next(data)                    # Remove header from dataset\n",
    "            \n",
    "            # Loop through all rows in .csv-file\n",
    "            tag_names = []\n",
    "            for row in data:\n",
    "                alternative_tags = []\n",
    "                if len(row) > 4:\n",
    "                    alternative_tags = [str(column).strip() for column in row[4:] if column]\n",
    "                tag_names.append(CrewLogTag(str(row[2]).strip(), alternative_tags))\n",
    "                \n",
    "            print(f\"\\nExtracted {len(tag_names)} main component(s) from '{csv_filename}'\")\n",
    "            return tag_names\n",
    "    \n",
    "    \n",
    "    # This function fetches CDF assets matching with the given list of CrewLogTag objects. It should only return assets\n",
    "    # that are relevant for the given data set IDs, meaning that it is either an asset, or has sub-assets that are part\n",
    "    # of those data sets, or has events from those same data sets\n",
    "    # Parameters:\n",
    "    # - 'tag_names' must be a list of CrewLogTag objects (e.g. [CrewLogTag('NN-AA-NNNNN'), ...])\n",
    "    #\n",
    "    def get_cdf_asset_ids(self, tag_names, data_set_ids):\n",
    "        print(f'Fetching CDF assets from data set(s) {data_set_ids}...')\n",
    "        asset_ids = []\n",
    "        \n",
    "        # Loop through list of tag names and search CDF for matching assets\n",
    "        for tag in tag_names:\n",
    "            # List all CDF assets matching the given tag name\n",
    "            assets = client.assets.list(name=tag.name, limit=-1)\n",
    "            #print(f'Found {len(assets)} assets searching for {tag.name}: {[asset.id for asset in assets]}')\n",
    "            tag_assets = [assets.copy()]\n",
    "            \n",
    "            # Check relevance with data set ids and removes assets that have no relevance to those data sets\n",
    "            if data_set_ids:\n",
    "                for asset in assets:\n",
    "                    # If asset is not part of data sets\n",
    "                    if asset.data_set_id not in data_set_ids:\n",
    "                        # If asset does not have sub assets within those same data sets\n",
    "                        if not client.assets.list(asset_subtree_ids=[asset.id], data_set_ids=data_set_ids, limit=1):\n",
    "                            # If asset, or its sub-assets, does not have events within those same data sets - remove that asset\n",
    "                            if not client.events.list(asset_subtree_ids=[asset.id], data_set_ids=data_set_ids, limit=1):\n",
    "                                tag_assets[0].remove(asset)\n",
    "            \n",
    "            # If no assets were found relevant - use alternative tags if available\n",
    "            if not tag_assets[0] and tag.alt_tags:\n",
    "                #print(f'Tag has alternative tags: {tag.alt_tags}')\n",
    "                for alt_tag in tag.alt_tags:\n",
    "                    tag_assets.append(client.assets.list(name=alt_tag, data_set_ids=data_set_ids, limit=-1))\n",
    "                #print(f'Remaining assets after considering alternative tags: {[asset.id for asset in tag_assets[0]]}')\n",
    "            \n",
    "            # If there's (still) duplicates - check if any of the duplicates have relations with eachother\n",
    "            # and remove unneccessary duplicates\n",
    "            temp_assets = tag_assets.copy()\n",
    "            for i, asset_list in enumerate(temp_assets):\n",
    "                if len(asset_list) > 1:\n",
    "                    duplicate_ids = [asset.id for asset in asset_list]\n",
    "                    for asset in asset_list:\n",
    "                        temp_asset = asset\n",
    "                        while temp_asset.parent_id:\n",
    "                            if temp_asset.parent_id in duplicate_ids:\n",
    "                                tag_assets[i].remove(temp_asset.parent())\n",
    "                                duplicate_ids.remove(temp_asset.parent_id)\n",
    "                                break\n",
    "                            temp_asset = temp_asset.parent()\n",
    "                    if len(duplicate_ids) > 1: print(f'Could not identify duplicates among {duplicate_ids}')\n",
    "            \n",
    "            # Return a list of asset IDs\n",
    "            for asset_list in tag_assets:\n",
    "                for asset in asset_list:\n",
    "                    asset_ids.append(asset.id)\n",
    "                    \n",
    "        print(f'Found {len(asset_ids)} assets.')\n",
    "        return asset_ids\n",
    "    \n",
    "    \n",
    "    # This function exports asset IDs and names to respective .csv-files in 'output' directory\n",
    "    def generate_csv_files(self):\n",
    "        \n",
    "        # Generate a .csv-file for each Aker BP asset\n",
    "        print(f'\\nGenerating .csv-files ...')\n",
    "        for akerbp_asset_abbr, asset_ids in self.asset_ids.items():\n",
    "            with open(f'output/asset_ids_{akerbp_asset_abbr.lower()}.csv', 'w') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(['ASSET_IDS', 'ASSET_NAME'])   # Header of .csv-file\n",
    "                for asset_id in asset_ids:\n",
    "                    row = [asset_id, client.assets.retrieve(id=asset_id).name]\n",
    "                    writer.writerow(row)\n",
    "        print(f'.csv-files generated.')\n",
    "    \n",
    "    \n",
    "    # Main function to fetch list of the found CDF asset IDs matching a given tag list, to be used with e.g. CrewLogEventFetcher()\n",
    "    # - 'akerbp_asset_abbr' must be a three letter Aker BP asset abbrieviation (e.g. 'ULA')\n",
    "    #\n",
    "    def fetch_assets(self, akerbp_asset_abbr):\n",
    "        tag_names = self.import_tags_from_csv(self.csv_filenames[akerbp_asset_abbr])\n",
    "        self.asset_ids[akerbp_asset_abbr] = self.get_cdf_asset_ids(tag_names, self.data_set_ids[akerbp_asset_abbr])\n",
    "        return self.asset_ids[akerbp_asset_abbr]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up event fetcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full example for setting up event fetching from Ula:\n",
    "```python\n",
    "my_asset_fetcher = CrewLogAssetFetcher()\n",
    "my_asset_fetcher.add_akerbp_asset('ULA', 'main_components_ula_abb_tags.csv', [2086908079872503])\n",
    "\n",
    "asset_ids = my_asset_fetcher.fetch_assets('ULA')\n",
    "\n",
    "my_fetcher = CrewLogEventFetcher()\n",
    "my_fetcher.add_akerbp_asset('ULA', my_fetcher.get_abb_events, [2086908079872503], asset_ids)\n",
    "\n",
    "events = my_fetcher.fetch_events('ULA')   # Fetches events in the time interval [shift start, current time]\n",
    "```\n",
    "The last line of code above will fetch all events from the start of the current shift up until the current time. To fetch new events you simply need to run the same line of code again at another time:\n",
    "```python\n",
    "events = my_fetcher.fetch_events('ULA')   # Fetches events in the time interval [last fetching time, current time]\n",
    "```\n",
    "NOTE: Remember that the `get_kongsberg_events` and `get_siemens_events` functions in the `CrewLogEventFetcher` class are yet to be implemented as their data is not available in CDF at this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted 219 main component(s) from 'main_components_ula_abb_tags.csv'\n",
      "Fetching CDF assets from data set(s) [2086908079872503]...\n",
      "Found 175 assets.\n",
      "\n",
      "Extracted 462 main component(s) from 'main_components_valhall.csv'\n",
      "Fetching CDF assets from data set(s) [140572846698809]...\n",
      "Found 366 assets.\n",
      "\n",
      "Extracted 517 main component(s) from 'main_components_skarv.csv'\n",
      "Fetching CDF assets from data set(s) []...\n",
      "Found 501 assets.\n",
      "\n",
      "Extracted 233 main component(s) from 'main_components_alvheim.csv'\n",
      "Fetching CDF assets from data set(s) []...\n",
      "Could not identify duplicates among [4909397956766959, 5576109327626046]\n",
      "Could not identify duplicates among [1361192871416397, 2175262956095244]\n",
      "Could not identify duplicates among [4887147706554168, 6680966522712542]\n",
      "Could not identify duplicates among [5794600446063807, 7313151598201456]\n",
      "Could not identify duplicates among [1515210526033923, 3969124812466527]\n",
      "Found 237 assets.\n",
      "\n",
      "Extracted 71 main component(s) from 'main_components_ivar_aasen.csv'\n",
      "Fetching CDF assets from data set(s) []...\n",
      "Could not identify duplicates among [403612373912141, 7955142513743002]\n",
      "Found 72 assets.\n",
      "\n",
      "Generating .csv-files ...\n",
      ".csv-files generated.\n"
     ]
    }
   ],
   "source": [
    "# Create the CrewLogEventFetcher object to be used for fetching events from CDF\n",
    "# NOTE: See the CrewLogEventFetcher class above for details on its functions\n",
    "#\n",
    "crewlog_event_fetcher = CrewLogEventFetcher()\n",
    "\n",
    "\n",
    "# These are the main setup parameters needed for fetching events from an Aker BP asset from CDF\n",
    "# All assets should have a 'get_function' from the CrewLogEventFetcher object, a list of 'cdf_data_set_ids' and\n",
    "# a .csv-file with tag names for the given Aker BP asset\n",
    "#\n",
    "# NOTE: When e.g. Digital Foundation for Skarv becomes available in CDF, we must add its data set ID under\n",
    "#      'cdf_data_set_ids' for 'SKA' below, just like we have done for 'ULA' and 'VAL'.\n",
    "#\n",
    "# CAUTION: The 'get_kongsberg_events' and 'get_siemens_events' functions are yet to be implemented in the\n",
    "#          CrewLogEventFetcher class. Use the 'get_abb_events' as an example when implementing these when\n",
    "#          Skarv, Alvheim and Ivar Aasen data becomes avaible in CDF and you have identified how their data\n",
    "#          must be filtered.\n",
    "#\n",
    "akerbp_assets = {\n",
    "    'ULA': {\n",
    "        'get_function': crewlog_event_fetcher.get_abb_events,        # Ula has ABB control system\n",
    "        'cdf_data_set_ids': [2086908079872503],                      # OPC UA data ULA (Digital Foundation dataset)\n",
    "        'csv_filename': 'main_components_ula_abb_tags.csv'\n",
    "    },\n",
    "    'VAL': {\n",
    "        'get_function': crewlog_event_fetcher.get_abb_events,        # Valhall has ABB control system\n",
    "        'cdf_data_set_ids': [140572846698809],                       # OPC UA data VAL (Digital Foundation dataset)\n",
    "        'csv_filename': 'main_components_valhall.csv'\n",
    "    },\n",
    "    'SKA': {\n",
    "        'get_function': crewlog_event_fetcher.get_kongsberg_events,  # Skarv has Kongsberg control system\n",
    "        'cdf_data_set_ids': [],\n",
    "        'csv_filename': 'main_components_skarv.csv'\n",
    "    },\n",
    "    'ALV': {\n",
    "        'get_function': crewlog_event_fetcher.get_kongsberg_events,  # Alvheim has Kongsberg control system\n",
    "        'cdf_data_set_ids': [],\n",
    "        'csv_filename': 'main_components_alvheim.csv'\n",
    "    },\n",
    "    'IAA': {\n",
    "        'get_function': crewlog_event_fetcher.get_siemens_events,    # Ivar Aasen has Siemens control system\n",
    "        'cdf_data_set_ids': [],\n",
    "        'csv_filename': 'main_components_ivar_aasen.csv'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create the CrewLogAssetFetcher object to be used for generating lists of relevant CDF asset IDs\n",
    "# NOTE: See the CrewLogAssetFetcher class above for details on its functions\n",
    "#\n",
    "crewlog_asset_fetcher = CrewLogAssetFetcher()\n",
    "\n",
    "for akerbp_asset_abbr, asset_data in akerbp_assets.items():\n",
    "    # Adds an Aker BP asset to the CrewLogAssetFetcher object\n",
    "    crewlog_asset_fetcher.add_akerbp_asset(\n",
    "        akerbp_asset_abbr,\n",
    "        asset_data['csv_filename'],\n",
    "        asset_data['cdf_data_set_ids']\n",
    "    )\n",
    "    \n",
    "    # Fetches a list of asset IDs from the given asset\n",
    "    asset_data['cdf_asset_ids'] = crewlog_asset_fetcher.fetch_assets(akerbp_asset_abbr)\n",
    "    \n",
    "    # Adds and Aker BP asset to the CrewLogEventFetcher object with the parameters declared in 'akerbp_assets' above\n",
    "    # as well as the list of asset IDs from the previous line\n",
    "    crewlog_event_fetcher.add_akerbp_asset(\n",
    "        akerbp_asset_abbr,\n",
    "        asset_data['get_function'],\n",
    "        asset_data['cdf_data_set_ids'],\n",
    "        asset_data['cdf_asset_ids']\n",
    "    )\n",
    "    \n",
    "# Generates a .csv-file for each Aker BP asset with a list of their respective CDF asset ids\n",
    "# NOTE: These are probably files that the backend in CrewLog needs when they will be implementing their own functionality\n",
    "crewlog_asset_fetcher.generate_csv_files()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function retrieves a CDF event by its event id\n",
    "def get_event(id):\n",
    "    return client.events.retrieve(id=id)\n",
    "\n",
    "# This function retrieves a CDF asset by its asset id\n",
    "def get_asset(id):\n",
    "    return client.assets.retrieve(id=id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function extracts tag names from a text string\n",
    "# Inputs:\n",
    "# string - text string (e.g. '23-KA-9103-M01_CB_travel_alarm')\n",
    "# field - all caps abbreviation of an Aker BP asset (e.g. 'VAL')\n",
    "#\n",
    "# Output: \n",
    "# list of found tag names in string, matching the given fields tagging convention\n",
    "# (e.g. ['23-KA-9103'])\n",
    "\n",
    "def extract_tag_names(string, field):\n",
    "    def default(string, field):\n",
    "        print(f\"There is no function for extracting tags for {field}\")\n",
    "        return None\n",
    "    \n",
    "    # Ula tags usually follow this format: A(AAA)-NNNN(N)(A)-(A)\n",
    "    def extract_ula_tag(string, field):\n",
    "        return re.search(r'[A-Z]+-\\d+([A-Z][A-Z]?|(-[A-Z]\\b)?)', string)\n",
    "    \n",
    "    # Valhall tags usually follow this format: NN-AA(A)-NNNN(NN)(A)\n",
    "    def extract_valhall_tag(string, field):\n",
    "        return re.search('[0-9][0-9]-[A-Z]+-\\d+[A-Z]?[A-Z]?', string)\n",
    "    \n",
    "    switcher = {\n",
    "        'ULA': extract_ula_tag,\n",
    "        'VAL': extract_valhall_tag\n",
    "    }\n",
    "    \n",
    "    x = re.split('_', string)\n",
    "    matches = []\n",
    "    for word in x:\n",
    "        y = switcher.get(field, default)(word, field)\n",
    "        if y: \n",
    "            matches.append(y.group())\n",
    "    if not matches: print(f'Could not identify any tags with {field} tagging convention in \"{string}\"')\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function looks for the field (Aker BP asset) of a CDF asset\n",
    "def get_field_from_asset(asset):\n",
    "    # The root asset usually holds information about the Aker BP installation\n",
    "    root_asset = get_asset(asset.root_id)\n",
    "    installation = root_asset.name\n",
    "    \n",
    "    if installation in ['VAL', 'VFN', 'VFS', 'VFW', 'HOD', 'HOP', 'VLA']:\n",
    "        return 'VAL'\n",
    "    elif installation in ['ULA', 'TAM']:\n",
    "        return 'ULA'\n",
    "    elif installation in ['SKA', 'ALV', 'IAA']:\n",
    "        return installation\n",
    "    \n",
    "    print(f'Found unexpected field from root asset: {installation}')\n",
    "    return installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function recursively searches for a parent asset of an event that is not an asset created by e.g. signal tags/subtags/softtags/etc.\n",
    "# \n",
    "# Example hierarchy:\n",
    "# Z-0501 (id: 8289785573229588)          <-- True parent\n",
    "#  LP-0561 (id: 4103300555352816)        <-- Some other ancestor (tag does not match)\n",
    "#    Z-0501-01 (id: 6791812333680596)    <-- Grandparent that comes from Aveva (still has signal tag)\n",
    "#      Z-0501-01 (id: 4728001758341600)  <-- Parent asset in OPC UA dataset (has signal tag)\n",
    "#        (event) Abnormal condition (source: Z-0501-01, id: 7491014714576560)\n",
    "\n",
    "def get_true_parent(event, print_hierarchy = False):\n",
    "    parent = None\n",
    "    source_name = event.metadata[\"source\"]\n",
    "    \n",
    "    # Store order of hierarchy for printing and troubleshooting purposes\n",
    "    hierarchy = [[f'(event) {event.description} (source: {source_name}, id: {event.id})'] for _ in range(len(event.asset_ids))]\n",
    "    \n",
    "    # Loop through all related CDF assets for the given event\n",
    "    for i, asset_id in enumerate(event.asset_ids):\n",
    "        temp_asset = get_asset(asset_id)\n",
    "        \n",
    "        # List of potential tag names following the given fields tagging convention, usually just one\n",
    "        tag_names = extract_tag_names(source_name, get_field_from_asset(temp_asset))   \n",
    "        \n",
    "        # Recursively search for a parent asset that matches with the desired tag name (up the CDF asset hierarchy)\n",
    "        j = 0\n",
    "        while temp_asset.parent_id and not parent and j < 5:\n",
    "            hierarchy[i].append(f'{temp_asset.name} (id: {temp_asset.id})')    # For printing and troubleshooting purposes\n",
    "            for name in tag_names:\n",
    "                # If the parent assets name is part of or equal to the desired tag name, we have found a match\n",
    "                # (e.g. if the found asset has a main equipment tag name, but the desired tag name is a redundancy tag with A/B/etc. at the end, we still consider it a match)\n",
    "                if temp_asset.name in name:\n",
    "                    parent = temp_asset\n",
    "                    if name != temp_asset.name: print(f'{temp_asset.name} will be used instead of {name}')   # To verify that non-exact matches still are relatives\n",
    "                    \n",
    "                    # For printing and troubleshooting purposes\n",
    "                    if print_hierarchy:\n",
    "                        for k in range(len(hierarchy[i])):\n",
    "                            indent = k*\"  \"\n",
    "                            print(indent + hierarchy[i][-(k+1)])\n",
    "                            \n",
    "                    return parent\n",
    "            temp_asset = get_asset(temp_asset.parent_id)\n",
    "            j += 1\n",
    "        \n",
    "        #if not parent: print(f'Could not find true parent of event {event.id} after {j} recursive steps using asset {asset_id} ({i+1}/{len(event.asset_ids)})')\n",
    "    #print(f'No true parents were found for event {event.id} (event had {len(event.asset_ids)} related CDF asset(s))')\n",
    "    \n",
    "    #if print_hierarchy: ...\n",
    "    \n",
    "    return parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function recursively searches for a parent asset that holds information that can determine a SAP FLOC prefix\n",
    "def get_floc_prefix(asset):\n",
    "    temp_asset = asset\n",
    "    \n",
    "    # FLOC prefix can often be found from an assets 'PLATFORM CODE' attribute\n",
    "    prefix = temp_asset.metadata.get('PLATFORM CODE', '')\n",
    "    \n",
    "    # Recursively search for a parent asset holding the 'PLATFORM CODE' property (up the CDF asset hierarchy)\n",
    "    i = 0\n",
    "    while temp_asset.parent_id and not prefix and i < 5:\n",
    "        temp_asset = get_asset(temp_asset.parent_id)\n",
    "        prefix = temp_asset.metadata.get('PLATFORM CODE', '')\n",
    "        i += 1\n",
    "    \n",
    "    #if not prefix: print(f'Could not find FLOC prefix for asset {asset.id} after {i} recursive steps')\n",
    "    return prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns the SAP FLOC of a CDF event\n",
    "def get_floc(event, print_hierarchy = False):\n",
    "    temp_floc = event.metadata[\"source\"]\n",
    "    true_parent = get_true_parent(event, print_hierarchy)\n",
    "    if true_parent:\n",
    "        temp_floc = true_parent.name\n",
    "    prefix = get_floc_prefix(true_parent if true_parent else get_asset(event.asset_ids[0]))\n",
    "    if prefix:\n",
    "        temp_floc = prefix + \"-\" + temp_floc\n",
    "    return temp_floc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function prints an event with the following format:\n",
    "#  <time> | <floc> | <object-description> | <event-description> | <severity> (<event-id>)\n",
    "def print_event(event):\n",
    "    time = event.metadata.get('activeTime', event.metadata['time'])\n",
    "    floc = get_floc(event)\n",
    "    object_desc = event.metadata.get('ObjectDescription', '**no object description**')\n",
    "    description = f'{event.metadata[\"message\"]}, {event.metadata.get(\"conditionName\", \"\")}'\n",
    "    severity = event.metadata['severity']\n",
    "    print(f'    {time} | {floc} | {object_desc} | {description} | {severity} (id: {event.id})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test of fetching alarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed while fetching events from VAL: 0:01:19.865211\n",
      "    9/29/2022 7:07:29 AM | VIP-48-NXI-82060G | IP XD8001 HighFuel | Alarm HH, High High | 902 (id: 7965098300933456)\n",
      "    9/29/2022 7:07:31 AM | VIP-48-NXI-82060C | IP XD8001 Alarm | Alarm HH, High High | 902 (id: 1424355083939100)\n",
      "    9/29/2022 7:08:42 AM | VIP-48-NXI-82060F | IP XD8001 LowFuel | Alarm HH, High High | 902 (id: 6246370064110145)\n",
      "    9/29/2022 7:39:19 AM | VPH-11-TIC-92306 | PH Interstg Htr Oil Out | <= 55.0 ºC Warning L, Low | 804 (id: 4185713949259738)\n",
      "    9/29/2022 7:53:01 AM | VPH-32-LT-95807 | PH TEG Surge Drum | <= 27.0 % Warning L, Low | 804 (id: 8324375927166473)\n",
      "    9/29/2022 7:59:40 AM | VPH-43-PT-96675 | PH TEG Transfer Pump Disch | <= 2.0 bar Warning L, Low | 804 (id: 5212396431861260)\n"
     ]
    }
   ],
   "source": [
    "akerbp_asset_abbr = 'VAL'\n",
    "timeref = datetime.datetime.now()\n",
    "#crewlog_event_fetcher.last_timestamps[akerbp_asset_abbr] -= datetime.timedelta(hours=12)\n",
    "events = crewlog_event_fetcher.fetch_events(akerbp_asset_abbr)\n",
    "delay = datetime.datetime.now() - timeref\n",
    "\n",
    "print(f'Time elapsed while fetching events from {akerbp_asset_abbr}: {delay}')\n",
    "if events:\n",
    "    for event in events:\n",
    "        print_event(event)\n",
    "else:\n",
    "    print('No events found.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
